{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --upgrade ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from time import sleep\n",
    "from component_store import GeneticAlgorithmComponent\n",
    "import numpy as np\n",
    "\n",
    "features = best_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "perf = pd.DataFrame(columns=[\"lookback\", \"train_start\", \"train_end\", \"test_year\", \"inds\", \"train_score\", \"test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_training_data([2023]).columns[:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = [0, 2, 3, 4]\n",
    "# features = [5, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "# features = [4, 7, 9, 11, 13, 15, 17, 19, 21]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_selector(get_training_data([2023]), features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_training_data([2023]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipe(train_start, train_end, test_year, features):\n",
    "    train_df = get_training_data([train_start + x for x in range(train_end-train_start+1)])\n",
    "    train_X = column_selector(train_df, features)\n",
    "    train_y = train_df['result']\n",
    "\n",
    "    if train_df.size == 0:\n",
    "        return\n",
    "\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(train_X, train_y)\n",
    "\n",
    "    test_df = get_training_data([test_year])\n",
    "    test_X = column_selector(test_df, features)\n",
    "    test_y = test_df['result']\n",
    "\n",
    "    # print(test_X)\n",
    "    # print(test_y)\n",
    "    # print(clf.predict(test_X))\n",
    "    # print(clf.predict_proba(test_X))\n",
    "\n",
    "    if test_df.size == 0:\n",
    "        return\n",
    "\n",
    "    train_score = clf.score(train_X, train_y)\n",
    "    test_score = clf.score(test_X, test_y)\n",
    "\n",
    "    return train_score, test_score, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score, test_score, _ = run_pipe(2019, 2022, 2023, features)\n",
    "train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for l in trange(1):\n",
    "    # print(\"lookback\")    \n",
    "    lookback = l + 5\n",
    "    for ty in trange(24-3 - lookback):\n",
    "        # print(f\"test_year: {test_year}\")\n",
    "        test_year = 2003 + lookback + ty\n",
    "        for feature in range(1):\n",
    "            # print(f\"feature: {feature}\")\n",
    "            train_start, train_end = test_year - lookback, test_year - 1\n",
    "\n",
    "            # print(lookback, train_start, train_end, test_year)\n",
    "            # sleep(0.1)\n",
    "\n",
    "            results = run_pipe(train_start, train_end, test_year, features)\n",
    "\n",
    "            if results is None:\n",
    "                continue\n",
    "            train_score, test_score, _ = results\n",
    "            \n",
    "            perf = pd.concat((\n",
    "                perf, \n",
    "                pd.DataFrame([[\n",
    "                    lookback, train_start, train_end, test_year,\n",
    "                    str(features), \n",
    "                    train_score, \n",
    "                    test_score\n",
    "                ]], columns=[\"lookback\", \"train_start\", \"train_end\", \"test_year\", \"inds\", \"train_score\", \"test_score\"])\n",
    "            ), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = perf[[\"lookback\", \"inds\", \"train_score\", \"test_score\"]].groupby(by=[\"lookback\", \"inds\"]).mean().sort_values(by=\"test_score\", ascending=False)\n",
    "grouped = grouped[\"test_score\"].reset_index().pivot(index=\"lookback\", columns=\"inds\", values=\"test_score\")\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(grouped.index, grouped.iloc[:, 0])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.loc[grouped.mean(axis=1).sort_values(ascending=False).index, grouped.mean(axis=0).sort_values(ascending=False).index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.7238805970149254, RandomForestClassifier())"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = run_pipe(2013, 2018, 2019, features)\n",
    "train_acc, test_acc, clf = results\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 6, 8, 10, 12, 14, 16, 18, 20]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_ADJEM</th>\n",
       "      <th>A_ADJOE</th>\n",
       "      <th>A_ADJDE</th>\n",
       "      <th>A_ADJ_T</th>\n",
       "      <th>A_Luck</th>\n",
       "      <th>A_SOS</th>\n",
       "      <th>A_OppO</th>\n",
       "      <th>A_OppD</th>\n",
       "      <th>A_NCSOS</th>\n",
       "      <th>B_ADJEM</th>\n",
       "      <th>B_ADJOE</th>\n",
       "      <th>B_ADJDE</th>\n",
       "      <th>B_ADJ_T</th>\n",
       "      <th>B_Luck</th>\n",
       "      <th>B_SOS</th>\n",
       "      <th>B_OppO</th>\n",
       "      <th>B_OppD</th>\n",
       "      <th>B_NCSOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>-4.13</td>\n",
       "      <td>102.1</td>\n",
       "      <td>106.2</td>\n",
       "      <td>71.1</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-7.85</td>\n",
       "      <td>98.8</td>\n",
       "      <td>106.7</td>\n",
       "      <td>6.15</td>\n",
       "      <td>-4.22</td>\n",
       "      <td>106.5</td>\n",
       "      <td>110.7</td>\n",
       "      <td>66.8</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-8.16</td>\n",
       "      <td>99.5</td>\n",
       "      <td>107.7</td>\n",
       "      <td>-1.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>11.55</td>\n",
       "      <td>109.7</td>\n",
       "      <td>98.2</td>\n",
       "      <td>70.8</td>\n",
       "      <td>0.051</td>\n",
       "      <td>5.56</td>\n",
       "      <td>107.3</td>\n",
       "      <td>101.7</td>\n",
       "      <td>1.55</td>\n",
       "      <td>7.61</td>\n",
       "      <td>108.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>70.8</td>\n",
       "      <td>0.060</td>\n",
       "      <td>5.00</td>\n",
       "      <td>106.9</td>\n",
       "      <td>101.9</td>\n",
       "      <td>-6.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>-3.20</td>\n",
       "      <td>107.4</td>\n",
       "      <td>110.6</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-2.85</td>\n",
       "      <td>104.8</td>\n",
       "      <td>107.6</td>\n",
       "      <td>3.23</td>\n",
       "      <td>-11.55</td>\n",
       "      <td>97.8</td>\n",
       "      <td>109.3</td>\n",
       "      <td>65.3</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-11.84</td>\n",
       "      <td>97.0</td>\n",
       "      <td>108.9</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>14.09</td>\n",
       "      <td>115.6</td>\n",
       "      <td>101.5</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-1.98</td>\n",
       "      <td>103.6</td>\n",
       "      <td>105.6</td>\n",
       "      <td>3.78</td>\n",
       "      <td>9.72</td>\n",
       "      <td>109.2</td>\n",
       "      <td>99.5</td>\n",
       "      <td>68.9</td>\n",
       "      <td>0.064</td>\n",
       "      <td>4.55</td>\n",
       "      <td>106.3</td>\n",
       "      <td>101.8</td>\n",
       "      <td>-1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>14.89</td>\n",
       "      <td>104.3</td>\n",
       "      <td>89.5</td>\n",
       "      <td>68.4</td>\n",
       "      <td>0.007</td>\n",
       "      <td>1.37</td>\n",
       "      <td>105.2</td>\n",
       "      <td>103.8</td>\n",
       "      <td>3.60</td>\n",
       "      <td>16.51</td>\n",
       "      <td>112.1</td>\n",
       "      <td>95.6</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>4.99</td>\n",
       "      <td>105.9</td>\n",
       "      <td>100.9</td>\n",
       "      <td>-3.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554</th>\n",
       "      <td>30.03</td>\n",
       "      <td>114.1</td>\n",
       "      <td>84.1</td>\n",
       "      <td>66.6</td>\n",
       "      <td>0.004</td>\n",
       "      <td>11.18</td>\n",
       "      <td>109.8</td>\n",
       "      <td>98.7</td>\n",
       "      <td>-5.39</td>\n",
       "      <td>32.85</td>\n",
       "      <td>124.5</td>\n",
       "      <td>91.6</td>\n",
       "      <td>70.2</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>4.46</td>\n",
       "      <td>106.9</td>\n",
       "      <td>102.5</td>\n",
       "      <td>1.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>26.81</td>\n",
       "      <td>122.5</td>\n",
       "      <td>95.6</td>\n",
       "      <td>65.9</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>13.16</td>\n",
       "      <td>110.3</td>\n",
       "      <td>97.1</td>\n",
       "      <td>4.09</td>\n",
       "      <td>34.22</td>\n",
       "      <td>123.4</td>\n",
       "      <td>89.2</td>\n",
       "      <td>59.4</td>\n",
       "      <td>0.050</td>\n",
       "      <td>11.18</td>\n",
       "      <td>109.2</td>\n",
       "      <td>98.1</td>\n",
       "      <td>-3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>25.00</td>\n",
       "      <td>120.9</td>\n",
       "      <td>95.9</td>\n",
       "      <td>67.9</td>\n",
       "      <td>0.008</td>\n",
       "      <td>12.23</td>\n",
       "      <td>110.7</td>\n",
       "      <td>98.5</td>\n",
       "      <td>2.63</td>\n",
       "      <td>34.22</td>\n",
       "      <td>123.4</td>\n",
       "      <td>89.2</td>\n",
       "      <td>59.4</td>\n",
       "      <td>0.050</td>\n",
       "      <td>11.18</td>\n",
       "      <td>109.2</td>\n",
       "      <td>98.1</td>\n",
       "      <td>-3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>30.03</td>\n",
       "      <td>114.1</td>\n",
       "      <td>84.1</td>\n",
       "      <td>66.6</td>\n",
       "      <td>0.004</td>\n",
       "      <td>11.18</td>\n",
       "      <td>109.8</td>\n",
       "      <td>98.7</td>\n",
       "      <td>-5.39</td>\n",
       "      <td>30.81</td>\n",
       "      <td>121.0</td>\n",
       "      <td>90.2</td>\n",
       "      <td>66.9</td>\n",
       "      <td>0.001</td>\n",
       "      <td>13.67</td>\n",
       "      <td>110.6</td>\n",
       "      <td>96.9</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>34.22</td>\n",
       "      <td>123.4</td>\n",
       "      <td>89.2</td>\n",
       "      <td>59.4</td>\n",
       "      <td>0.050</td>\n",
       "      <td>11.18</td>\n",
       "      <td>109.2</td>\n",
       "      <td>98.1</td>\n",
       "      <td>-3.24</td>\n",
       "      <td>30.03</td>\n",
       "      <td>114.1</td>\n",
       "      <td>84.1</td>\n",
       "      <td>66.6</td>\n",
       "      <td>0.004</td>\n",
       "      <td>11.18</td>\n",
       "      <td>109.8</td>\n",
       "      <td>98.7</td>\n",
       "      <td>-5.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      A_ADJEM  A_ADJOE  A_ADJDE  A_ADJ_T  A_Luck  A_SOS  A_OppO  A_OppD  \\\n",
       "1112    -4.13    102.1    106.2     71.1   0.061  -7.85    98.8   106.7   \n",
       "1113    11.55    109.7     98.2     70.8   0.051   5.56   107.3   101.7   \n",
       "1114    -3.20    107.4    110.6     65.0   0.064  -2.85   104.8   107.6   \n",
       "1115    14.09    115.6    101.5     71.3   0.025  -1.98   103.6   105.6   \n",
       "1116    14.89    104.3     89.5     68.4   0.007   1.37   105.2   103.8   \n",
       "...       ...      ...      ...      ...     ...    ...     ...     ...   \n",
       "2554    30.03    114.1     84.1     66.6   0.004  11.18   109.8    98.7   \n",
       "2555    26.81    122.5     95.6     65.9  -0.015  13.16   110.3    97.1   \n",
       "2556    25.00    120.9     95.9     67.9   0.008  12.23   110.7    98.5   \n",
       "2557    30.03    114.1     84.1     66.6   0.004  11.18   109.8    98.7   \n",
       "2558    34.22    123.4     89.2     59.4   0.050  11.18   109.2    98.1   \n",
       "\n",
       "      A_NCSOS  B_ADJEM  B_ADJOE  B_ADJDE  B_ADJ_T  B_Luck  B_SOS  B_OppO  \\\n",
       "1112     6.15    -4.22    106.5    110.7     66.8   0.040  -8.16    99.5   \n",
       "1113     1.55     7.61    108.6    101.0     70.8   0.060   5.00   106.9   \n",
       "1114     3.23   -11.55     97.8    109.3     65.3  -0.008 -11.84    97.0   \n",
       "1115     3.78     9.72    109.2     99.5     68.9   0.064   4.55   106.3   \n",
       "1116     3.60    16.51    112.1     95.6     65.0   0.011   4.99   105.9   \n",
       "...       ...      ...      ...      ...      ...     ...    ...     ...   \n",
       "2554    -5.39    32.85    124.5     91.6     70.2  -0.001   4.46   106.9   \n",
       "2555     4.09    34.22    123.4     89.2     59.4   0.050  11.18   109.2   \n",
       "2556     2.63    34.22    123.4     89.2     59.4   0.050  11.18   109.2   \n",
       "2557    -5.39    30.81    121.0     90.2     66.9   0.001  13.67   110.6   \n",
       "2558    -3.24    30.03    114.1     84.1     66.6   0.004  11.18   109.8   \n",
       "\n",
       "      B_OppD  B_NCSOS  \n",
       "1112   107.7    -1.86  \n",
       "1113   101.9    -6.49  \n",
       "1114   108.9     1.19  \n",
       "1115   101.8    -1.07  \n",
       "1116   100.9    -3.71  \n",
       "...      ...      ...  \n",
       "2554   102.5     1.87  \n",
       "2555    98.1    -3.24  \n",
       "2556    98.1    -3.24  \n",
       "2557    96.9     3.24  \n",
       "2558    98.7    -5.39  \n",
       "\n",
       "[134 rows x 18 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_df = get_training_data([2019])\n",
    "test_X = column_selector(test_df, features)\n",
    "test_y = test_df['result']\n",
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_year = 2019\n",
    "df = pd.read_csv(\"../data/cleaned_bracket_data.csv\", index_col=0)\n",
    "df = df[(df[\"year\"] == test_year) & (df[\"round\"] == 1)]\n",
    "start_team_names = df[[\"team1\", \"team2\"]].reset_index().melt(id_vars=['index'], value_vars=['team1', 'team2']).sort_values([\"index\", \"variable\"]).reset_index(drop=True)[\"value\"]\n",
    "start_team_names = pd.merge(start_team_names, df[[\"team1\", \"team1seed\"]], how=\"left\", left_on=\"value\", right_on=\"team1\").rename({\"team1seed\":\"SEED\"}, axis=1).drop(\"team1\", axis=1)\n",
    "start_team_names = pd.merge(start_team_names, df[[\"team2\", \"team2seed\"]], how=\"left\", left_on=\"value\", right_on=\"team2\").drop(\"team2\", axis=1)\n",
    "start_team_names.loc[start_team_names[\"SEED\"].isna(), \"SEED\"] = start_team_names[\"team2seed\"]\n",
    "start_team_names = start_team_names.drop(\"team2seed\", axis=1)\n",
    "\n",
    "# features_df = pd.read_csv(\"../data/kenpom.csv\", index_col=0)\n",
    "# features_df = features_df[features_df[\"YEAR\"] == test_year]\n",
    "\n",
    "# teams_df = pd.merge(start_team_names, features_df, how=\"left\", left_on=\"value\", right_on=\"TEAM\")\n",
    "# teams_df = pd.concat((teams_df.iloc[:, -3:], teams_df.iloc[:, 1:2], teams_df.iloc[:, 2:3], teams_df.iloc[:, 6:-4]), axis=1)\n",
    "# # stats_2 = pd.concat((df_2.iloc[:, -4:], df_2.iloc[:, 3:4], df_2.iloc[:, 7:-5]), axis=1)\n",
    "# teams_df_1 = teams_df.iloc[0::2].add_prefix(\"A_\").reset_index(drop=True)\n",
    "# teams_df_2 = teams_df.iloc[1::2].add_prefix(\"B_\").reset_index(drop=True)\n",
    "# teams_df = pd.concat((teams_df_1, teams_df_2), axis=1)\n",
    "# print(teams_df.shape)\n",
    "# X_df = column_selector(teams_df, features)\n",
    "\n",
    "# X_df = make_X_from_teams(start_team_names, test_year, features)\n",
    "\n",
    "# pred_probs = clf.predict_proba(X_df)\n",
    "# r = np.random.rand(pred_probs.shape[0])\n",
    "# r = (pred_probs[:, 0] < r).astype(int)\n",
    "# pred_inds = np.arange(pred_probs.shape[0]) * 2 + r\n",
    "# next_team_names = start_team_names.iloc[pred_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgenerate_brackets_np\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_team_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_year\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vauda\\Documents\\work\\PS\\march_madness_24\\src\\utils.py:75\u001b[0m, in \u001b[0;36mgenerate_brackets_np\u001b[1;34m(clf, features, start_team_names, year, num_brackets)\u001b[0m\n\u001b[0;32m     73\u001b[0m team_names \u001b[38;5;241m=\u001b[39m start_team_names\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m team_names\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 75\u001b[0m     team_names, results \u001b[38;5;241m=\u001b[39m run_round_np(clf, features, start_team_names, year)\n\u001b[0;32m     76\u001b[0m     bracket \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([bracket, results])\n\u001b[0;32m     77\u001b[0m all_brackets \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([all_brackets, bracket\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generate_brackets_np(clf, features, start_team_names, test_year, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_team_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_counts = {k:0 for k in [i+1 for i in range(16)]}\n",
    "seed_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_brackets = np.zeros((0,63))\n",
    "for i in range(100):\n",
    "    bracket = np.zeros((0,))\n",
    "    team_names = start_team_names\n",
    "\n",
    "    while team_names.shape[0] > 1:\n",
    "        team_names, results = run_round_np(team_names)\n",
    "        bracket = np.concatenate([bracket, results])\n",
    "    seed_counts[int(team_names[\"SEED\"].iloc[0])] += 1\n",
    "    # print(bracket)\n",
    "    all_brackets = np.concatenate([all_brackets, bracket.reshape((1, -1))], axis=0)\n",
    "all_brackets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 1000\n",
    "bracket_timer = 0\n",
    "\n",
    "for i in range(num_trials):\n",
    "    team_names = start_team_names\n",
    "    t0 = perf_counter()\n",
    "    while team_names.shape[0] > 1:\n",
    "        team_names, results = run_round_np(team_names)\n",
    "    t1 = perf_counter()\n",
    "    bracket_timer += t1 - t0\n",
    "    seed_counts[int(team_names[\"SEED\"].iloc[0])] += 1\n",
    "    \n",
    "print(f\"Average time of {bracket_timer / num_trials} s per bracket generated!\\nDistribution of winners:\\n\")\n",
    "seed_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gac = GeneticAlgorithmComponent(10, 10)\n",
    "population = gac.execute({\"model\": clf}, init_pop, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc, test_acc, clf = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf[perf[\"inds\"] == \"[5, 6, 8, 10, 12, 14, 16, 18, 20, 22]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [5, 6, 8, 10, 12, 14, 16, 18, 20, 22, 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.mean(axis=0).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.mean(axis=1).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_training_data([2023]).columns[6:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf.sort_values(by=\"test_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start = 2002\n",
    "train_end = 2022\n",
    "test_year = 2023\n",
    "features = [x+1 for x in range(21)]\n",
    "results = pd.DataFrame()\n",
    "\n",
    "for i in trange(21):\n",
    "    train_df = get_training_data([train_start + x for x in range(train_end-train_start+1)])\n",
    "    train_X = column_selector(train_df, features)\n",
    "    train_y = train_df['result']\n",
    "\n",
    "\n",
    "\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(train_X, train_y)\n",
    "\n",
    "    test_df = get_training_data([test_year])\n",
    "    test_X = column_selector(test_df, features)\n",
    "    test_y = test_df['result']\n",
    "\n",
    "    # print(test_X)\n",
    "    # print(test_y)\n",
    "    # print(clf.predict(test_X))\n",
    "    # print(clf.predict_proba(test_X))\n",
    "\n",
    "\n",
    "    train_score = clf.score(train_X, train_y)\n",
    "    test_score = clf.score(test_X, test_y)\n",
    "\n",
    "    print(train_score, test_score)\n",
    "    importances = pd.DataFrame(clf.feature_importances_, columns=[\"importances\"], index=features+features).reset_index().groupby(\"index\").mean().sort_values(by=\"importances\")\n",
    "    results = pd.concat((results, pd.DataFrame([[worst, train_score, test_score]])))\n",
    "    worst = importances.index[0]\n",
    "    features.remove(worst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst = pd.DataFrame(clf.feature_importances_, columns=[\"importances\"], index=features+features).reset_index().groupby(\"index\").mean().sort_values(by=\"importances\").index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.remove(worst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "madness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
